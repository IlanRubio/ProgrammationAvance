# Programmation Avanc√©e - Rapport n¬∞2

RUBIO Ilan INFA-3

## Introduction

Ce rapport examine l'application de la technique de Monte Carlo pour estimer la valeur de œÄ. 
La m√©thode consiste √† g√©n√©rer des points al√©atoires dans un espace d√©fini, 
puis √† calculer le rapport entre les points situ√©s √† l'int√©rieur d'une r√©gion d'int√©r√™t et ceux situ√©s √† l'int√©rieur de l'espace total. 
Cette approche est particuli√®rement utile pour des probl√©matiques complexes o√π une solution analytique est difficile √† obtenir.

Pour r√©aliser ce rapport, des intelligences artificielles ont √©t√© utilis√©es.

### Configuration machine

Pour effectuer toutes les mesures, j'ai utilis√© une machine en G26 avec la configuration suivante :

| Composant         | D√©tails                                 |
|-------------------|-----------------------------------------|
| RAM               | 32 GB                                   |
| Processeur        | Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz |
| Coeurs            | 4 coeurs physique                       |
| Cache de niveau 1 | 256 Ko                                  |
| Cache de niveau 2 | 1,0 Mo                                  |
| Cache de niveau 3 | 8,0 Mo                                  |

## Monte Carlo pour calculer œÄ

Calcul de Pi par une m√©thode de Monte Carlo.

### G√©n√©ralit√©s

#### Monte Carlo Histoire
La m√©thode de Monte Carlo tire son nom du fameux casino de Monte Carlo, en raison de son utilisation intensive du hasard. 
Elle a √©t√© largement d√©velopp√©e au cours du XXe si√®cle, notamment par les chercheurs du projet Manhattan pour mod√©liser des ph√©nom√®nes complexes.

Aujourd'hui, cette m√©thode est employ√©e dans de nombreux domaines scientifiques, notamment en physique, en finance et en g√©ophysique. 
Par exemple, les g√©ophysiciens utilisent cette technique pour mod√©liser l'√©coulement de l'eau dans les nappes souterraines.

#### Principe du calcul de œÄ par Monte Carlo


L'id√©e fondamentale est d'utiliser la probabilit√© d'un point al√©atoirement plac√© dans un carr√© pour estimer œÄ.

1. Consid√©rons un carr√© de c√¥t√© 1 inscrit dans un rep√®re orthonorm√©.

2. Un quart de cercle est trac√© √† l'int√©rieur de ce carr√©, avec un rayon de 1.

3. On g√©n√®re un grand nombre de points al√©atoires √† l'int√©rieur du carr√©.

4. On compte combien de ces points tombent √† l'int√©rieur du quart de cercle, en v√©rifiant si la condition :
```x¬≤+y¬≤ <= 1 ``` est satisfaite.

Le rapport entre le nombre de points √† l'int√©rieur du quart de cercle et le nombre total de points permet d'estimer œÄ en utilisant la relation suivante :
```œÄ ‚âà 4 * ncible/ntotal```

L'aire du quart de disque s'√©crit A d/4 = œÄr¬≤/4 = œÄ/4

![MonteCarlo](MonteCarlo.jpg)


**Figure 1 :** illustre le tirage al√©atoire de point xp de coordonn√©es
(xp,yp) o√π xp, yp suivent une loi (]0,1[).

La probabilit√© qu'un point Xp soit dans le quart de disque est telle que 

```P(Xp|dp<1)=(Ad/4)/Ac = œÄ/4```

On effectue n_total tirage. Si n_total est grand alors on approche 
```P(Xp|dp<1) ‚âà ncible/ntotal```.

Avec ncible le nombre de points dans la cible.

On peut alors approcher œÄ par ```œÄ‚âà4* ncible/n_total```.


### Algorithme  : Monte Carlo

On √©crit alors l'algorithme :
```
n_cible=0
//g√©n√©rer et compter n_cible
for p=0 : n_total-1
    g√©n√©rer xp;
    g√©n√©rer yp;
    if xp¬≤+yp¬≤ < 1 then
        ncible ++;
    endif
endfor
//calculer PI
PI = 4*(n_cible/ntotal);
```
Dans cette version de l'algorithme tout est execut√© s√©quentiellement.
Afin de l'am√©liorer et pouvoir le parall√©liser, il faut dans un premier temps, d√©terminer quelles sont les diff√©rentes t√¢ches.

On remarque alors 2 t√¢ches : 
1. **T√¢che 1** : G√©n√©rer et compter n_cible


Cette premi√®re t√¢che contient alors 2 sous t√¢ches : 
* Sous t√¢che 1 : G√©n√©rer xp et yp
* Sous t√¢che 2 : Incr√©menter ncible si ````xp¬≤+yp¬≤ < 1````

2. **T√¢che 2** : Calculer pi

Dans ces t√¢ches, on peut alors remarquer des d√©pendances.
* La t√¢che 2 ne peut √™tre effectu√©e tant que la t√¢che 1 n'est pas termin√©e.
* La sous t√¢che 2 d√©pend de la premi√®re, le point doit √™tre g√©n√©r√© avant de savoir s'il est dans la zone souhait√©e.

En d√©terminant ces d√©pendances, on peut alors remarquer une section critique dans cet algrtihme :
```
if xp¬≤+yp¬≤ < 1 then
        ncible ++;
    endif
```
On peut donc en d√©duire que ```ncible ``` est une ressource critique. Cette ressource doit ainsi √™tre prot√©g√©e pour √©viter des conflits.

### Parall√©lisation
Pour ce code, on a utilis√© deux paradigmes, le parall√©lisme d'it√©ration parall√®le (parall√©lisme de boucle) et le paradigme Master/Worker.

#### Parall√©lisme de boucle

PLe parall√©lisme de boucle est un paradigme de programmation parall√®le qui permet d'ex√©cuter plusieurs it√©rations d'une boucle simultan√©ment. 
Dans le cas de la m√©thode de Monte Carlo, chaque it√©ration g√©n√®re un point al√©atoire et v√©rifie s'il se situe √† l'int√©rieur du cercle. 
En ex√©cutant ces it√©rations en parall√®le, on peut acc√©l√©rer le calcul de œÄ.

On peut retrouver ce paradigme avec le code Assignement102.

#### Master/Worker
Le paradigme Master/Worker fonctionne ainsi :

* Workers : Chaque worker se voit attribuer une t√¢che sp√©cifique. Dans notre cas, il s'agit de r√©aliser n tirages al√©atoires.
* Master : Il distribue les t√¢ches aux workers et traite les r√©sultats. Ici, il effectue le calcul : ```4 * ncible/ntotal```
* Nous avons donc n processus workers ind√©pendants ex√©cutant simultan√©ment n_total tirages al√©atoires chacun. 
Une fois tous les workers ayant termin√© leur t√¢che, le master estime la valeur de œÄ.

![MasterWorker](MasterWorker.jpg)
Ce sch√©ma repr√©sente le fonctionnement de ce paradigme. 

On peut retrouver ce code avec le code Pi.java.

## Java

### Assignement102
![UML Assignement102](Assignement102.jpg)

#### Fonctionnement


La classe ```PiMonteCarlo```g√®re l'ex√©cution du calcul de Monte-Carlo en utilisant le parall√©lisme avec l'API Concurrent.
Cette classe contient une classe interne ```MonteCarlo```. Cette classe impl√©mente Runnable.

* Simule un tirage de coordonn√©es (x, y) et v√©rifie s'il tombe dans le quart de cercle.
* Si ```x¬≤+y¬≤ <= 1 ```, alors le point est dans le cercle et on incr√©mente nAtomSuccess.

La classe ```Assignment102``` : 
* Instancie un objet ```PiMonteCarlo``` avec deux param√®etres le nombre de lancers et le nombre de threads.
* Mesure le temps d'ex√©cution.
* Retourne le r√©sultat

#### Scalabilit√© forte
![Graphe de scalabilit√© forte](Graphe/Scalabite_forte_assignement.png)
On peut voir que la scalabilit√© forte est tr√®s mauvaise. On remarque qu'elle est presque constante malgr√© une baisse 
lorsque l'on passe √† 6 processus.

On peut donc en d√©duire que ce code n'est pas efficace. C'est-√†-dire que la parall√©lisation
ne permet pas de rendre ce code plus performant et ainsi d'estimer Pi plus rapidement.

#### Scalabilit√© faible
![Graphe de scalabilit√© faible](Graphe/Scalabite_faible_assignement.png)

√Ä partir de 2 threads, la performance se d√©grade fortement, atteignant presque z√©ro 


#### Comparaison
![comparaison scalabilite](Graphe/Comparaison_assignement.png)

On peut remarquer que les graphes de scalabilit√©s fortes et faibles sont presque √©quivalentes.
Cela peut s'expliquer par le fait la parall√©lisation de code n'est pas efficace.
En effet, la majeure partie de temps de calculs de ce fait dans la section critique.
Cela emp√™che de pouvoir parall√©liser efficacement ce code.

#### Erreur
![Graphe erreur](Graphe/erreur_assignement.png)

On peut remarquer que l'erreur a une tendance √† diminuer lorsque le nombre de processus augmente.

#### Am√©lioration

Ce code ne se parall√©lise pas tr√®s bien, car une majorit√© des calculs se font en ressource critique.
Une mani√®re de l'am√©liorer est de faire les calculs pour les points hors de la cible. Ainsi, on effectuera un calcul sur 25% au lieu de 75% en ressource critique.

### Pi.java
![UML Pi.java](Uml_Pi.png)

#### Fonctionnement

Repose sur l'impl√©mentation de Callable et de Futures.

``Classe Pi``
* Elle r√©cup√®re les arguments d'entr√©e (nombre d'it√©rations et nombre de threads).
* Elle ex√©cute l'approximation via la classe Master.

``Classe Master``
* Cette classe orchestre l'ex√©cution parall√®le des t√¢ches en : 
  * Cr√©ant une liste de t√¢ches ``List<Callable<Long>>``
  * Les ex√©cutant avec un ``ExecutorService``
  * R√©cup√©rant les r√©sultats et calculant ùúã
* S'assure de l'ex√©cution parall√®le des t√¢ches.
* S'occupe de la r√©cup√©ration des r√©sultats et calcul de œÄ.

``Classe Worker``
* Chaque thread ex√©cute une instance de ``Worker`` qui :
  * G√©n√®re ``numIterations`` points al√©atoires.
  * Compte combien tombent dans le quart de cercle.

#### Scalabilit√© forte

![Graphe de scalabilit√© forte](Graphe/Scalabite_forte_pi.png)

Les courbes montrent que la scalabilit√© forte est meilleure avec un plus grand nombre de points (12e8 > 12e7 > 12e6).
On remarque √©galement qu'elle est bonne jusqu'√† 4 processus puis qu'elle diminue en augmentant le nombre de processus.
#### Scalabilit√© faible

![Graphe de scalabilit√© faible](Graphe/Scalabite_faible_pi.png)
La courbe d√©croissante confirme un probl√®me de scalabilit√© faible : au lieu d‚Äôacc√©l√©rer l‚Äôex√©cution, l‚Äôajout de threads r√©duit l‚Äôefficacit√©.

#### Comparaison

![Graphe de comparaison scalabilite](Graphe/Comparaison_pi.png)

#### Erreur
![Graphe erreur](Graphe/erreur_pi.png)

On peut remarquer que l'erreur a une tendance √† diminuer lorsque le nombre de processus augmente.

### MasterSocket / WorkerSocket

![UML Master](MasterSocket.jpg)
![UML socket](Uml_socket.png)

#### Fonctionnement
``Classe MasterSocket``

Cette classe orchestre l'ex√©cution distribu√©e des t√¢ches en :
* Se connectant aux Workers via des sockets TCP/IP.
* Envoyant le nombre d‚Äôit√©rations √† ex√©cuter.
* Attendant et collectant les r√©sultats des Workers.
* Calculant l‚Äôestimation de ùúã √† partir des r√©sultats.
* Assure la gestion des connexions r√©seau et la coordination des Workers.

``Classe WorkerSocket``

Chaque Worker est un serveur qui :
* Attend une connexion d‚Äôun MasterSocket.
* Re√ßoit le nombre d‚Äôit√©rations √† effectuer.
* Lance le calcul Monte Carlo :
  * G√©n√®re numIterations points al√©atoires.
  * Compte combien tombent dans le quart de cercle.
  * Envoie son r√©sultat au Master.
  * Se termine lorsque le Master envoie le message "END".

``Communication & Synchronisation``

* Le Master envoie des requ√™tes TCP aux Workers.
* Les Workers retournent leurs r√©sultats au Master.
* Le Master attend la r√©ponse de tous les Workers avant de calculer la valeur finale de ùúã.

Cette architecture repose sur un mod√®le distribu√© avec sockets, ce qui permet d'ex√©cuter le calcul sur plusieurs machines en parall√®le. 

#### Scalabilit√© forte

![Graphe de scalabilit√© forte](Graphe/Scalabite_forte_socket.png)

* Lorsque la charge de travail est plus √©lev√©e (12e7), le speedup est meilleur, ce qui signifie que le programme b√©n√©ficie mieux du parall√©lisme.
* √Ä l'inverse, avec une charge plus faible (12e6), la scalabilit√© est moins bonne, indiquant un ratio communication/calcul d√©favorable.

Une charge de travail plus importante am√©liore la scalabilit√©, mais on ne parvient pas √† atteindre un speedup id√©al.

#### Scalabilit√© faible

![Graphe de scalabilit√© faible](Graphe/Scalabite_faible_socket.png)

Le speedup d√©cro√Æt fortement avec l'augmentation du nombre de threads. 
Cela signifie que l'ajout de threads ralentit plut√¥t qu'il n'am√©liore les performances.

#### Comparaison

![Graphe de comparaison scalabilite](Graphe/Comparaison_socket.png)


#### Erreur

![Graphe erreur](Graphe/erreur_socket.png)

On observe que l'erreur m√©diane (points rouges) diminue globalement √† mesure que le nombre de processus augmente,
ce qui est coh√©rent avec l'approche Monte Carlo : plus il y a d'it√©rations (ou de points simul√©s), plus l'estimation de œÄ est pr√©cise.

L'augmentation du nombre de Workers am√©liore la pr√©cision du calcul, mais il peut y avoir une certaine variance en raison de la nature probabiliste de Monte Carlo.

### Dans la salle G26

Pour se rapprocher au mieux de la courbe id√©ale, on utilise plusieurs machines de la salle G26.

Un poste sera le master et les autres postes seront les diff√©rents workers.

#### Installation 
Pour commencer, il faut aller sur centos.
Il faut alors ex√©cuter plusieurs commandes afin d'avoir le projet et de pouvoir le rendre fonctionnel.

Il faut installer java avec ```sudo yum install java-devel```.

Pour pouvoir se connecter aux autres machines, il faut alors d√©sactiver le firewall. On peut le faire avec la commande
```sudo systemctl stop firewalld```

Il faut ensuite r√©cup√©rer le projet avec ```gitclone``` et ensuite la compiler avec la commande ```make```.
Cela lancera le fichier Makefile qui compilera ainsi les diff√©rentes classes.

#### Exp√©rience

On va faire une exp√©rience de scalabilit√© faible. 
On va donc faire des calculs avec le nombre de processus allant de 1 √† 64.

| **Nombre de processus** | **Nombre de thread** | **Temps (ms)** | **Erreur**            |
|-------------------------|----------------------|----------------|-----------------------|
| 1                       | 2e9                  | 68039          | x                     |
| 2                       | 4e9                  | x              | x                     |
| 4                       | 8e9                  | 70436          | 1.074792104395961E-5  |
| 8                       | 16e9                 | 70450          | 4.610508550924495E-6  |
| 16                      | 32e9                 | 70484          | 1.2763940615949628E-6 |
| 32                      | 64e9                 | 71908          | 2.8263219557848443E-6 |
| 64                      | 128e9                | 70890          | 1.3741649324992772E-6 |

![Graphe de scalabilit√© faible](Graphe/Scalabite_faible_partage.png)

Avec cette m√©thode, on peut observer que l'on a un tr√®s bon graphe de scalabilit√© faible.
On peut en d√©duire que cette parall√©lisation est tr√®s efficace.


## Performance 

Pour √©tudier, les performances des codes, on utilise les normes **ISO/IEC 25010** et **ISO/IEC 25022**.

On utilise deux mod√®les pour √©valuer les syst√®mes que l'on a mis en place.

### Quality In Use Model

Ce mod√®le permet d‚Äô√©valuer la qualit√© d‚Äôun logiciel selon les besoins l‚Äôutilisateur final. 
Il met l‚Äôaccent sur l‚Äôexp√©rience r√©elle d‚Äôutilisation en prenant en compte divers crit√®res essentiels, tels que l‚Äôefficacit√©, la fiabilit√© ou encore le confort. 
Ce mod√®le vise √† mesurer la capacit√© d‚Äôun logiciel √† r√©pondre aux besoins des utilisateurs tout en minimisant les risques li√©s √† son utilisation.


| **Crit√®re**                                                                                | **D√©finition**                                                                                                      |
|--------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|
| **Efficacit√© (Efficiency)**                                                                | Capacit√© du syst√®me √† permettre √† l‚Äôutilisateur d‚Äôaccomplir ses t√¢ches en utilisant les ressources ad√©quates.       |
| **Efficacit√© fonctionnelle (Effectiveness)**                                               | Capacit√© du logiciel √† aider l‚Äôutilisateur √† atteindre ses objectifs de mani√®re correcte et compl√®te.               |
| **Utilit√© (Usefulness)**                                                                   | Pertinence du logiciel dans l‚Äôaccomplissement de ses fonctions .                                                    |
| **Fiabilit√© et confiance (Trust)**                                                         | Degr√© de confiance de l‚Äôutilisateur dans la stabilit√© et la fiabilit√© du logiciel .                                 |
| **Exp√©rience utilisateur agr√©able (Pleasure)**                                             | Niveau de satisfaction et de plaisir ressenti lors de l‚Äôutilisation, en particulier pour les nouveaux utilisateurs. |
| **Confort d‚Äôutilisation (Comfort)**                                                        | Facilit√© d‚Äôutilisation du logiciel, notamment en termes d‚Äôergonomie et de modularit√©.                               |
| **Risques √©conomiques (Economic risk)**                                                    | Co√ªt li√© √† la maintenance du logiciel, aux mises √† jour et aux √©ventuels probl√®mes financiers associ√©s.             |
| **R√©duction des risques pour la sant√© et la s√©curit√© (Health and safety risk mitigation)** | Minimisation des dangers potentiels pour les utilisateurs.                                                          |
| **R√©duction des impacts environnementaux (Environmental risk mitigation)**                 | Pr√©vention des risques pour l‚Äôenvironnement.                                                                        |
| **Ad√©quation au contexte (Context completeness)**                                          | Capacit√© du logiciel √† remplir efficacement son r√¥le dans un contexte d‚Äôutilisation sp√©cifique.                     |
| **Flexibilit√© (Flexibility)**                                                              | Adaptabilit√© du logiciel √† diff√©rents usages ou besoins sans n√©cessiter de modifications majeures.                  |



### Product Quality Model

Le Product Quality Model est un mod√®le qui permet d‚Äô√©valuer la qualit√© d‚Äôun logiciel, ind√©pendamment de son utilisation finale. 
Contrairement au Quality In Use Model, qui se concentre sur l‚Äôexp√©rience utilisateur, le Product Quality Model analyse les caract√©ristiques internes et externes du logiciel pour d√©terminer s‚Äôil est bien con√ßu et performant.

Ce mod√®le repose sur plusieurs crit√®res d√©finis notamment par la norme ISO/IEC 25010, qui est une √©volution de la norme ISO/IEC 9126. 
Voici les principales caract√©ristiques de la qualit√© d‚Äôun logiciel selon ce mod√®le :

| **Caract√©ristique**                                      | **D√©finition**                                                                                                                      |
|----------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------|
| **Fonctionnalit√©** (*Functional Suitability*)            | Capacit√© du logiciel √† fournir des fonctions qui r√©pondent aux besoins sp√©cifi√©s de mani√®re compl√®te et correcte.                   |
| **Fiabilit√©** (*Reliability*)                            | Capacit√© du logiciel √† fonctionner sans d√©faillance dans des conditions sp√©cifiques pendant une p√©riode donn√©e.                     |
| **Performance et efficacit√©** (*Performance Efficiency*) | Utilisation optimale des ressources syst√®me pour garantir une bonne r√©activit√© et un temps d‚Äôex√©cution acceptable.                  |
| **Compatibilit√©** (*Compatibility*)                      | Capacit√© du logiciel √† fonctionner correctement dans diff√©rents environnements et √† interagir avec d‚Äôautres syst√®mes.               |
| **Utilisabilit√©** (*Usability*)                          | Facilit√© avec laquelle un utilisateur peut comprendre, apprendre et utiliser le logiciel efficacement.                              |
| **S√©curit√©** (*Security*)                                | Protection des donn√©es et du syst√®me contre les acc√®s non autoris√©s et les attaques.                                                |
| **Maintenabilit√©** (*Maintainability*)                   | Facilit√© de modification du logiciel pour corriger des erreurs, am√©liorer ses performances ou ajouter de nouvelles fonctionnalit√©s. |
| **Portabilit√©** (*Portability*)                          | Capacit√© du logiciel √† √™tre transf√©r√© et utilis√© sur diff√©rents environnements sans n√©cessiter de modifications importantes.        |

## D√©finition

* **Speedup** : L‚Äôacc√©l√©ration Sp est le gain de vitesse d‚Äôex√©cution en fonction du nombre
  de processus P. On l‚Äôexprime comme le rapport du temps d‚Äô√©x√©cution sur
  un processus T1, sur le temps d‚Äôex√©cution sur P processus, Tp. On le calcule avec ```Sp = T1/Tp```
  On peut le repr√©senter avec la courbe suivante :
  ![Graphe speedup](SpeedUp.png)

* **Scalabilit√© forte** : La scalabilit√© forte √©value la capacit√© d‚Äôun programme √† diminuer son temps d‚Äôex√©cution lorsque le nombre de c≈ìurs augmente, tout en conservant une charge de travail constante.
  Elle mesure ainsi l‚Äôefficacit√© avec laquelle le programme utilise les ressources suppl√©mentaires.

* **Scalabilit√© faible** : La scalabilit√© faible mesure la capacit√© d‚Äôun programme √† maintenir un temps d‚Äôex√©cution stable lorsque la charge de travail et le nombre de c≈ìurs augmentent.
  Elle √©value dans quelle mesure le programme peut traiter efficacement une charge de travail croissante en exploitant davantage de ressources.

* **ISO/IEC 25010** : La norme **ISO/IEC 25010** est un standard international qui d√©finit un mod√®le de qualit√© pour l'√©valuation des logiciels et des syst√®mes informatiques.
  Elle appartient √† la famille des normes SQuaRE (Software Product Quality Requirements and Evaluation).

* **ISO/IEC 25022** : La norme ISO/IEC 25022 fait partie de la s√©rie SQuaRE (Software Product Quality Requirements and Evaluation) et se concentre sur l'√©valuation de la qualit√© en usage des syst√®mes et logiciels.

* **Future** : Une Future est un objet qui repr√©sente le r√©sultat d'une t√¢che asynchrone qui s'ex√©cutera dans le futur.
  Il agit comme un conteneur pour un r√©sultat qui n'est pas encore disponible.
  Les Futures permettent de :
  * V√©rifier si la t√¢che est termin√©e
  * Attendre que la t√¢che se termine et r√©cup√©rer le r√©sultat
  

## Conclusion

Ce rapport a explor√© la m√©thode de Monte Carlo pour estimer la valeur de œÄ et ses diff√©rentes impl√©mentations en programmation parall√®le et distribu√©e.
Nous avons analys√© plusieurs approches, du parall√©lisme de boucle √† l‚Äôarchitecture Master/Worker avec sockets, afin d‚Äô√©valuer leur impact sur la scalabilit√© et la performance.

Les r√©sultats montrent que la parall√©lisation de Monte Carlo n'est pas toujours efficace en raison des sections critiques limitant les gains de performance. 
L‚Äôapproche Master/Worker, bien que plus scalable, souffre d‚Äôun co√ªt de communication non n√©gligeable. L‚Äô√©tude des m√©triques de performance √† l‚Äôaide des normes ISO/IEC 25010 et ISO/IEC 25022 a permis de mieux comprendre les forces et limites de chaque impl√©mentation.

En conclusion, bien que la m√©thode de Monte Carlo soit une solution √©l√©gante pour l‚Äôapproximation de œÄ, son efficacit√© en parall√®le d√©pend fortement de l‚Äôarchitecture utilis√©e et de la gestion des ressources critiques.

Enfin, on a pu constater que la m√©thode qui utilise le mieux la parall√©lisation est le code Master/Worker socket. Si l'on ex√©cute le code sur diff√©rente machine, 
donc plusieurs workers, la parall√©lisation fonctionne mieux, car on peut ainsi utiliser plus de c≈ìurs diff√©rents.